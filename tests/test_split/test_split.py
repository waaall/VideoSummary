"""å­—å¹•åˆ†å‰²æ¨¡å—æµ‹è¯• - ä¸¥æ ¼è¾¹ç¼˜ç”¨ä¾‹

æµ‹è¯• app/core/split/split.py ä¸­çš„æ ¸å¿ƒåŠŸèƒ½
"""

import pytest

from app.core.asr.asr_data import ASRData, ASRDataSeg
from app.core.split.split import SubtitleSplitter, preprocess_segments


class TestPreprocessEdgeCases:
    """æµ‹è¯• preprocess_segments è¾¹ç¼˜æƒ…å†µ"""

    def test_unicode_extremes(self):
        """æµ‹è¯•æç«¯Unicodeå­—ç¬¦"""
        segments = [
            ASRDataSeg(
                text="ğŸ˜€ğŸŒğŸ‰", start_time=0, end_time=1000
            ),  # Emoji (å¯èƒ½è¢«å½“ä½œæ ‡ç‚¹)
            ASRDataSeg(text="Ù…Ø±Ø­Ø¨Ø§", start_time=1000, end_time=2000),  # é˜¿æ‹‰ä¼¯æ–‡
            ASRDataSeg(text="ĞŸÑ€Ğ¸Ğ²ĞµÑ‚", start_time=2000, end_time=3000),  # ä¿„æ–‡
            ASRDataSeg(text="à¸ªà¸§à¸±à¸ªà¸”à¸µ", start_time=3000, end_time=4000),  # æ³°æ–‡
        ]
        result = preprocess_segments(segments)
        # Emojiå¯èƒ½è¢«è¯†åˆ«ä¸ºæ ‡ç‚¹ï¼Œæ‰€ä»¥åº”è¯¥ >= 3
        assert len(result) >= 3

    def test_mixed_punctuation_types(self):
        """æµ‹è¯•æ··åˆæ ‡ç‚¹ç±»å‹"""
        segments = [
            ASRDataSeg(text="...", start_time=0, end_time=500),
            ASRDataSeg(text="ï¼ï¼ï¼", start_time=500, end_time=1000),  # ä¸­æ–‡æ ‡ç‚¹
            ASRDataSeg(text="...", start_time=1000, end_time=1500),
            ASRDataSeg(text="ï¼Ÿï¼Ÿï¼Ÿ", start_time=1500, end_time=2000),
        ]
        result = preprocess_segments(segments)
        assert len(result) == 0  # å…¨æ˜¯æ ‡ç‚¹

    def test_zero_duration_segments(self):
        """æµ‹è¯•é›¶æ—¶é•¿ç‰‡æ®µ"""
        segments = [
            ASRDataSeg(text="Hello", start_time=1000, end_time=1000),
            ASRDataSeg(text="World", start_time=1000, end_time=1000),
        ]
        result = preprocess_segments(segments)
        assert len(result) == 2

    def test_overlapping_timestamps(self):
        """æµ‹è¯•é‡å æ—¶é—´æˆ³"""
        segments = [
            ASRDataSeg(text="First", start_time=0, end_time=2000),
            ASRDataSeg(text="Overlap", start_time=1000, end_time=3000),
            ASRDataSeg(text="Third", start_time=2500, end_time=4000),
        ]
        result = preprocess_segments(segments)
        assert len(result) == 3

    def test_reversed_timestamps(self):
        """æµ‹è¯•å€’åºæ—¶é—´æˆ³"""
        segments = [
            ASRDataSeg(text="Reversed", start_time=2000, end_time=1000),
        ]
        result = preprocess_segments(segments)
        assert len(result) == 1

    def test_very_long_text(self):
        """æµ‹è¯•è¶…é•¿æ–‡æœ¬(>1000å­—ç¬¦)"""
        long_text = "æµ‹è¯•" * 1000
        segments = [ASRDataSeg(text=long_text, start_time=0, end_time=10000)]
        result = preprocess_segments(segments)
        assert len(result) == 1
        assert len(result[0].text) > 1000

    def test_whitespace_only_segments(self):
        """æµ‹è¯•çº¯ç©ºæ ¼/åˆ¶è¡¨ç¬¦/æ¢è¡Œç¬¦"""
        segments = [
            ASRDataSeg(text="   ", start_time=0, end_time=1000),
            ASRDataSeg(text="\t\t\t", start_time=1000, end_time=2000),
            ASRDataSeg(text="\n\n", start_time=2000, end_time=3000),
            ASRDataSeg(text="Valid", start_time=3000, end_time=4000),
        ]
        result = preprocess_segments(segments)
        # åº”è¯¥ç§»é™¤çº¯ç©ºç™½ï¼Œä¿ç•™"Valid"
        assert len(result) >= 1

    def test_mixed_case_with_numbers(self):
        """æµ‹è¯•å¤§å°å†™æ··åˆå’Œæ•°å­—"""
        segments = [
            ASRDataSeg(text="Test123ABC", start_time=0, end_time=1000),
            ASRDataSeg(text="456XYZ789", start_time=1000, end_time=2000),
        ]
        result = preprocess_segments(segments, need_lower=True)
        assert "test123abc" in result[0].text.lower()

    def test_special_characters(self):
        """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦"""
        segments = [
            ASRDataSeg(text="@#$%^&*()", start_time=0, end_time=1000),
            ASRDataSeg(text="<>[]{}\\|", start_time=1000, end_time=2000),
        ]
        result = preprocess_segments(segments)
        # ç‰¹æ®Šå­—ç¬¦åº”è¯¥è¢«è¯†åˆ«ä¸ºæ ‡ç‚¹æˆ–ä¿ç•™
        assert len(result) <= 2

    def test_newlines_and_tabs_in_text(self):
        """æµ‹è¯•æ–‡æœ¬ä¸­çš„æ¢è¡Œå’Œåˆ¶è¡¨ç¬¦"""
        segments = [
            ASRDataSeg(text="Line1\nLine2\tTab", start_time=0, end_time=1000),
        ]
        result = preprocess_segments(segments)
        assert len(result) == 1


class TestSubtitleSplitterEdgeCases:
    """æµ‹è¯• SubtitleSplitter è¾¹ç¼˜æƒ…å†µ"""

    def test_extremely_short_segments(self):
        """æµ‹è¯•æçŸ­ç‰‡æ®µ(1-2ä¸ªå­—)"""
        segments = [
            ASRDataSeg(text=f"å­—{i}", start_time=i * 100, end_time=(i + 1) * 100)
            for i in range(100)
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(
            thread_num=1, model="gpt-4o-mini", max_word_count_cjk=20
        )
        result = splitter.split_subtitle(asr_data)

        assert len(result.segments) < len(segments)  # åº”è¯¥åˆå¹¶äº†

    def test_extremely_long_single_segment(self):
        """æµ‹è¯•è¶…é•¿å•ä¸ªç‰‡æ®µ(500å­—)"""
        long_text = "ä»Šå¤©æˆ‘ä»¬æ¥è®²ä¸€è®²äººå·¥æ™ºèƒ½çš„å‘å±•å†å²å’Œæœªæ¥è¶‹åŠ¿ã€‚" * 50  # çº¦500å­—
        segments = [ASRDataSeg(text=long_text, start_time=0, end_time=60000)]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(
            thread_num=1, model="gpt-4o-mini", max_word_count_cjk=20
        )
        result = splitter.split_subtitle(asr_data)

        # åº”è¯¥è¢«åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µ
        assert len(result.segments) > 10

    def test_alternating_long_short_segments(self):
        """æµ‹è¯•é•¿çŸ­ç‰‡æ®µäº¤æ›¿"""
        segments = [
            ASRDataSeg(text="æˆ‘", start_time=0, end_time=100),
            ASRDataSeg(
                text="ä»Šå¤©æˆ‘ä»¬æ¥è®²ä¸€è®²äººå·¥æ™ºèƒ½çš„å‘å±•å†å²" * 5,
                start_time=100,
                end_time=10000,
            ),
            ASRDataSeg(text="å¥½", start_time=10000, end_time=10100),
            ASRDataSeg(
                text="æœºå™¨å­¦ä¹ ç®—æ³•çš„æ ¸å¿ƒåŸç†å’Œå®é™…åº”ç”¨" * 5,
                start_time=10100,
                end_time=20000,
            ),
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini", max_word_count_cjk=20)
        result = splitter.split_subtitle(asr_data)

        assert len(result.segments) > len(segments)

    def test_all_same_timestamp(self):
        """æµ‹è¯•æ‰€æœ‰ç‰‡æ®µæ—¶é—´æˆ³ç›¸åŒ"""
        segments = [
            ASRDataSeg(text=f"Text{i}", start_time=1000, end_time=2000)
            for i in range(10)
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        result = splitter.split_subtitle(asr_data)

        assert isinstance(result, ASRData)

    def test_large_time_gaps(self):
        """æµ‹è¯•å¤§æ—¶é—´é—´éš”(>10ç§’)"""
        segments = [
            ASRDataSeg(text="ç¬¬ä¸€æ®µ", start_time=0, end_time=1000),
            ASRDataSeg(text="ç¬¬äºŒæ®µ", start_time=20000, end_time=21000),  # 19ç§’é—´éš”
            ASRDataSeg(text="ç¬¬ä¸‰æ®µ", start_time=50000, end_time=51000),  # 29ç§’é—´éš”
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        result = splitter.split_subtitle(asr_data)

        assert len(result.segments) >= 3

    def test_1000_segments_stress(self):
        """å‹åŠ›æµ‹è¯•: 1000ä¸ªç‰‡æ®µ"""
        segments = [
            ASRDataSeg(
                text=f"è¿™æ˜¯ç¬¬{i}æ®µæµ‹è¯•æ–‡æœ¬å†…å®¹",
                start_time=i * 1000,
                end_time=(i + 1) * 1000,
            )
            for i in range(1000)
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini", max_word_count_cjk=20)
        result = splitter.split_subtitle(asr_data)

        assert isinstance(result, ASRData)
        assert len(result.segments) > 0

    def test_mixed_language_segments(self):
        """æµ‹è¯•æ··åˆè¯­è¨€ç‰‡æ®µ"""
        segments = [
            ASRDataSeg(text="Helloä½ å¥½ã“ã‚“ã«ã¡ã¯", start_time=0, end_time=1000),
            ASRDataSeg(text="Worldä¸–ç•Œì„¸ê³„", start_time=1000, end_time=2000),
            ASRDataSeg(text="Ù…Ø±Ø­Ø¨Ø§ĞŸÑ€Ğ¸Ğ²ĞµÑ‚", start_time=2000, end_time=3000),
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        result = splitter.split_subtitle(asr_data)

        # æ··åˆè¯­è¨€å¯èƒ½è¢«åˆå¹¶ï¼Œæ‰€ä»¥åªè¦æœ‰ç»“æœå³å¯
        assert len(result.segments) >= 1

    def test_numbers_only_segments(self):
        """æµ‹è¯•çº¯æ•°å­—ç‰‡æ®µ"""
        segments = [
            ASRDataSeg(text="123456789", start_time=0, end_time=1000),
            ASRDataSeg(text="3.14159265", start_time=1000, end_time=2000),
            ASRDataSeg(text="2024å¹´12æœˆ31æ—¥", start_time=2000, end_time=3000),
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        result = splitter.split_subtitle(asr_data)

        # æ•°å­—å¯èƒ½è¢«åˆå¹¶ï¼Œåªè¦æœ‰ç»“æœå³å¯
        assert len(result.segments) >= 1

    def test_repeated_text_segments(self):
        """æµ‹è¯•é‡å¤æ–‡æœ¬"""
        repeated_text = "é‡å¤çš„å†…å®¹"
        segments = [
            ASRDataSeg(text=repeated_text, start_time=i * 1000, end_time=(i + 1) * 1000)
            for i in range(50)
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        result = splitter.split_subtitle(asr_data)

        assert len(result.segments) > 0


class TestSplitterParameters:
    """æµ‹è¯•åˆ†å‰²å™¨å‚æ•°è¾¹ç•Œ"""

    def test_max_word_count_zero(self):
        """æµ‹è¯•æœ€å¤§å­—æ•°ä¸º0(å¯èƒ½è¢«å¿½ç•¥æˆ–ä½¿ç”¨é»˜è®¤å€¼)"""
        segments = [ASRDataSeg(text="æµ‹è¯•æ–‡æœ¬", start_time=0, end_time=1000)]
        asr_data = ASRData(segments)

        try:
            splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini", max_word_count_cjk=0,
            )
            result = splitter.split_subtitle(asr_data)
            # å¦‚æœä¸æŠ›å¼‚å¸¸ï¼Œåº”è¯¥è¿”å›æœ‰æ•ˆç»“æœ
            assert isinstance(result, ASRData)
        except (ValueError, AssertionError):
            # ä¹Ÿå¯èƒ½æŠ›å‡ºå¼‚å¸¸
            pass

    def test_max_word_count_very_large(self):
        """æµ‹è¯•æœ€å¤§å­—æ•°è¶…å¤§(10000)"""
        segments = [ASRDataSeg(text="æµ‹è¯•" * 100, start_time=0, end_time=10000)]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini", max_word_count_cjk=10000,
        )
        result = splitter.split_subtitle(asr_data)

        # è¶…å¤§é™åˆ¶åº”è¯¥ä¸åˆ†å‰²
        assert len(result.segments) <= 2

    def test_max_word_count_exactly_matches(self):
        """æµ‹è¯•å­—æ•°æ°å¥½ç­‰äºé™åˆ¶"""
        text = "æµ‹" * 20  # æ°å¥½20å­—
        segments = [ASRDataSeg(text=text, start_time=0, end_time=2000)]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini", max_word_count_cjk=20,
        )
        result = splitter.split_subtitle(asr_data)

        assert len(result.segments) >= 1


class TestMergeShortSegments:
    """æµ‹è¯•åˆå¹¶çŸ­ç‰‡æ®µè¾¹ç¼˜æƒ…å†µ"""

    def test_all_segments_very_short(self):
        """æµ‹è¯•å…¨æ˜¯è¶…çŸ­ç‰‡æ®µ(1-2å­—)"""
        segments = [
            ASRDataSeg(text="æˆ‘", start_time=i * 100, end_time=(i + 1) * 100)
            for i in range(100)
        ]

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        splitter.merge_short_segment(segments)

        # åº”è¯¥è¢«åˆå¹¶æˆæ›´å°‘çš„ç‰‡æ®µ
        assert len(segments) < 100

    def test_mixed_short_and_long(self):
        """æµ‹è¯•çŸ­ç‰‡æ®µå’Œé•¿ç‰‡æ®µæ··åˆ"""
        segments = [
            ASRDataSeg(text="çŸ­", start_time=0, end_time=100),
            ASRDataSeg(
                text="è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„ç‰‡æ®µå†…å®¹" * 10, start_time=100, end_time=5000
            ),
            ASRDataSeg(text="çŸ­", start_time=5000, end_time=5100),
        ]

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        original_len = len(segments)
        splitter.merge_short_segment(segments)

        # çŸ­ç‰‡æ®µå¯èƒ½è¢«åˆå¹¶
        assert len(segments) <= original_len

    def test_alternating_short_long_pattern(self):
        """æµ‹è¯•äº¤æ›¿çš„çŸ­é•¿æ¨¡å¼"""
        segments = []
        for i in range(50):
            # çŸ­ç‰‡æ®µ
            segments.append(
                ASRDataSeg(text="çŸ­", start_time=i * 2000, end_time=i * 2000 + 100)
            )
            # é•¿ç‰‡æ®µ
            segments.append(
                ASRDataSeg(
                    text="è¿™æ˜¯ä¸€ä¸ªæ¯”è¾ƒé•¿çš„ç‰‡æ®µ",
                    start_time=i * 2000 + 100,
                    end_time=(i + 1) * 2000,
                )
            )

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        splitter.merge_short_segment(segments)

        assert len(segments) > 0


class TestStopAndThreading:
    """æµ‹è¯•åœæ­¢å’Œçº¿ç¨‹æ§åˆ¶"""

    def test_stop_before_start(self):
        """æµ‹è¯•æœªå¼€å§‹å°±åœæ­¢"""
        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        assert splitter.is_running is True

        splitter.stop()
        assert splitter.is_running is False

    def test_stop_during_processing(self):
        """æµ‹è¯•å¤„ç†è¿‡ç¨‹ä¸­åœæ­¢"""
        # åˆ›å»ºå¤§é‡æ•°æ®
        segments = [
            ASRDataSeg(text=f"æµ‹è¯•{i}", start_time=i * 100, end_time=(i + 1) * 100)
            for i in range(1000)
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")

        # ç«‹å³åœæ­¢
        splitter.stop()

        # å°è¯•å¤„ç†(åº”è¯¥å¿«é€Ÿè¿”å›æˆ–æŠ›å‡ºå¼‚å¸¸)
        try:
            result = splitter.split_subtitle(asr_data)
            # å¦‚æœæˆåŠŸè¿”å›ï¼Œåº”è¯¥æ˜¯ç©ºçš„æˆ–éƒ¨åˆ†ç»“æœ
            assert isinstance(result, ASRData)
        except Exception:
            # å…è®¸æŠ›å‡ºå¼‚å¸¸
            pass

    def test_multiple_stop_calls(self):
        """æµ‹è¯•å¤šæ¬¡è°ƒç”¨stop"""
        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")

        splitter.stop()
        splitter.stop()
        splitter.stop()

        assert splitter.is_running is False


class TestTimestampIntegrity:
    """æµ‹è¯•æ—¶é—´æˆ³å®Œæ•´æ€§"""

    def test_no_negative_durations(self):
        """æµ‹è¯•åˆ†å‰²åæ— è´Ÿæ—¶é•¿"""
        segments = [
            ASRDataSeg(
                text="ä»Šå¤©å¤©æ°”å¾ˆå¥½æˆ‘ä»¬ä¸€èµ·å»å…¬å›­ç©å§", start_time=0, end_time=5000
            )
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        result = splitter.split_subtitle(asr_data)

        for seg in result.segments:
            assert seg.end_time >= seg.start_time

    def test_no_gaps_in_timeline(self):
        """æµ‹è¯•æ—¶é—´è½´æ— é—´éš™(å¯¹äºè¿ç»­ç‰‡æ®µ)"""
        segments = [
            ASRDataSeg(text="ç¬¬ä¸€æ®µ", start_time=0, end_time=1000),
            ASRDataSeg(text="ç¬¬äºŒæ®µ", start_time=1000, end_time=2000),
            ASRDataSeg(text="ç¬¬ä¸‰æ®µ", start_time=2000, end_time=3000),
        ]
        asr_data = ASRData(segments)

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        result = splitter.split_subtitle(asr_data)

        # éªŒè¯æ—¶é—´è¿ç»­æ€§
        for i in range(len(result.segments) - 1):
            # å…è®¸å°é—´éš™ï¼Œä½†ä¸åº”æœ‰å¤§è·³è·ƒ
            gap = result.segments[i + 1].start_time - result.segments[i].end_time
            assert gap >= 0  # ä¸åº”é‡å å¤ªå¤š

    def test_preserves_total_duration(self):
        """æµ‹è¯•ä¿æŒæ€»æ—¶é•¿"""
        segments = [ASRDataSeg(text="æµ‹è¯•æ–‡æœ¬" * 50, start_time=0, end_time=10000)]
        asr_data = ASRData(segments)

        original_duration = segments[0].end_time - segments[0].start_time

        splitter = SubtitleSplitter(thread_num=1, model="gpt-4o-mini")
        result = splitter.split_subtitle(asr_data)

        # æ€»æ—¶é•¿åº”è¯¥æ¥è¿‘åŸå§‹æ—¶é•¿
        if result.segments:
            total_duration = (
                result.segments[-1].end_time - result.segments[0].start_time
            )
            assert abs(total_duration - original_duration) < 1000  # å…è®¸1ç§’è¯¯å·®
